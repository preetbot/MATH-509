{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genre Classifier\n",
    "## This is the code for the genre classification model. It classifies samples of songs in the GTZAN dataset into 10 different genres using a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "UNd7lgvASXLc"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I-5yndyoSaSS",
    "outputId": "b00d0971-ab67-4729-9af7-5b7261d02aed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "eHtMOHKESXLh"
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"/content/drive/MyDrive/Colab Notebooks/data_10.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created the X and y variables for the dataset, which include the mfcc features and their labels. For example, mfcc features for one song sample would be labelled 'Blues'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "9Q7Hnx_aSXLi"
   },
   "outputs": [],
   "source": [
    "with open(DATA_PATH, \"r\") as fp:\n",
    "    data = json.load(fp)\n",
    "    # convert lists to numpy arrays\n",
    "    X = np.array(data[\"mfcc\"])\n",
    "    y = np.array(data[\"labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "g3irTxiKSXLj"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the neural network using a LSTM input layer. The hidden layer has a default rectified linear unit activation function. Output layer of 10 neurons for each genre in the dataset with a softmax activation function. Dropout layers were placed after the input layer and last 2 hidden layers to reduce overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jEaITcGuSXLk",
    "outputId": "813418c3-3d2d-44d9-fae4-e791101ef127"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 128)               72704     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 48)                3120      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 48)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                490       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101,082\n",
      "Trainable params: 101,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build network topology\n",
    "input_shape=(X.shape[1],X.shape[2])\n",
    "model = keras.Sequential()\n",
    "model.add(LSTM(128,input_shape=input_shape))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(48, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used adam optimization algorithm along with sparse categorical cross entropy loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wg8DxGIeSXLm",
    "outputId": "7f59db40-91ab-4fa5-96e4-a4bba1c819a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 128)               72704     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 48)                3120      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 48)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                490       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101,082\n",
      "Trainable params: 101,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimiser = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimiser, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model to the training set, and validated on the test set. The overall accuracy after 50 epochs was 72.40% with validation accuracy of 66%. There is slight overfitting however the model seems fine to present at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c7cC1kG5SXLn",
    "outputId": "2412eb5e-9226-4a9b-ab43-91329b81c0b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "203/203 [==============================] - 29s 142ms/step - loss: 1.1800 - accuracy: 0.5883 - val_loss: 1.1442 - val_accuracy: 0.5981\n",
      "Epoch 2/50\n",
      "203/203 [==============================] - 26s 130ms/step - loss: 1.1691 - accuracy: 0.5918 - val_loss: 1.1431 - val_accuracy: 0.5987\n",
      "Epoch 3/50\n",
      "203/203 [==============================] - 26s 130ms/step - loss: 1.1574 - accuracy: 0.5945 - val_loss: 1.1396 - val_accuracy: 0.6030\n",
      "Epoch 4/50\n",
      "203/203 [==============================] - 26s 129ms/step - loss: 1.1433 - accuracy: 0.6065 - val_loss: 1.1315 - val_accuracy: 0.6076\n",
      "Epoch 5/50\n",
      "203/203 [==============================] - 26s 130ms/step - loss: 1.1371 - accuracy: 0.6077 - val_loss: 1.1252 - val_accuracy: 0.6024\n",
      "Epoch 6/50\n",
      "203/203 [==============================] - 26s 130ms/step - loss: 1.1361 - accuracy: 0.6048 - val_loss: 1.1240 - val_accuracy: 0.6064\n",
      "Epoch 7/50\n",
      "203/203 [==============================] - 27s 134ms/step - loss: 1.1296 - accuracy: 0.6052 - val_loss: 1.1159 - val_accuracy: 0.6127\n",
      "Epoch 8/50\n",
      "203/203 [==============================] - 27s 133ms/step - loss: 1.1216 - accuracy: 0.6103 - val_loss: 1.1148 - val_accuracy: 0.6090\n",
      "Epoch 9/50\n",
      "203/203 [==============================] - 27s 131ms/step - loss: 1.1140 - accuracy: 0.6145 - val_loss: 1.1173 - val_accuracy: 0.6073\n",
      "Epoch 10/50\n",
      "203/203 [==============================] - 26s 130ms/step - loss: 1.1043 - accuracy: 0.6085 - val_loss: 1.0979 - val_accuracy: 0.6141\n",
      "Epoch 11/50\n",
      "203/203 [==============================] - 26s 130ms/step - loss: 1.1029 - accuracy: 0.6159 - val_loss: 1.1056 - val_accuracy: 0.6087\n",
      "Epoch 12/50\n",
      "203/203 [==============================] - 26s 130ms/step - loss: 1.0783 - accuracy: 0.6253 - val_loss: 1.1019 - val_accuracy: 0.6144\n",
      "Epoch 13/50\n",
      "203/203 [==============================] - 27s 132ms/step - loss: 1.0763 - accuracy: 0.6213 - val_loss: 1.0880 - val_accuracy: 0.6170\n",
      "Epoch 14/50\n",
      "203/203 [==============================] - 27s 132ms/step - loss: 1.0688 - accuracy: 0.6344 - val_loss: 1.0862 - val_accuracy: 0.6204\n",
      "Epoch 15/50\n",
      "203/203 [==============================] - 27s 134ms/step - loss: 1.0563 - accuracy: 0.6370 - val_loss: 1.0914 - val_accuracy: 0.6199\n",
      "Epoch 16/50\n",
      "203/203 [==============================] - 27s 134ms/step - loss: 1.0483 - accuracy: 0.6385 - val_loss: 1.0800 - val_accuracy: 0.6187\n",
      "Epoch 17/50\n",
      "203/203 [==============================] - 27s 131ms/step - loss: 1.0452 - accuracy: 0.6374 - val_loss: 1.0761 - val_accuracy: 0.6201\n",
      "Epoch 18/50\n",
      "203/203 [==============================] - 27s 132ms/step - loss: 1.0134 - accuracy: 0.6487 - val_loss: 1.0743 - val_accuracy: 0.6310\n",
      "Epoch 19/50\n",
      "203/203 [==============================] - 27s 131ms/step - loss: 1.0199 - accuracy: 0.6453 - val_loss: 1.0837 - val_accuracy: 0.6307\n",
      "Epoch 20/50\n",
      "203/203 [==============================] - 28s 137ms/step - loss: 1.0243 - accuracy: 0.6484 - val_loss: 1.0751 - val_accuracy: 0.6287\n",
      "Epoch 21/50\n",
      "203/203 [==============================] - 27s 133ms/step - loss: 0.9933 - accuracy: 0.6567 - val_loss: 1.0649 - val_accuracy: 0.6301\n",
      "Epoch 22/50\n",
      "203/203 [==============================] - 27s 131ms/step - loss: 1.0102 - accuracy: 0.6411 - val_loss: 1.0625 - val_accuracy: 0.6330\n",
      "Epoch 23/50\n",
      "203/203 [==============================] - 27s 132ms/step - loss: 1.0170 - accuracy: 0.6541 - val_loss: 1.0643 - val_accuracy: 0.6307\n",
      "Epoch 24/50\n",
      "203/203 [==============================] - 27s 131ms/step - loss: 1.0074 - accuracy: 0.6490 - val_loss: 1.0607 - val_accuracy: 0.6330\n",
      "Epoch 25/50\n",
      "203/203 [==============================] - 26s 130ms/step - loss: 0.9869 - accuracy: 0.6569 - val_loss: 1.0576 - val_accuracy: 0.6293\n",
      "Epoch 26/50\n",
      "203/203 [==============================] - 27s 134ms/step - loss: 0.9706 - accuracy: 0.6624 - val_loss: 1.0521 - val_accuracy: 0.6344\n",
      "Epoch 27/50\n",
      "203/203 [==============================] - 27s 132ms/step - loss: 0.9772 - accuracy: 0.6630 - val_loss: 1.0564 - val_accuracy: 0.6339\n",
      "Epoch 28/50\n",
      "203/203 [==============================] - 26s 130ms/step - loss: 0.9638 - accuracy: 0.6701 - val_loss: 1.0450 - val_accuracy: 0.6347\n",
      "Epoch 29/50\n",
      "203/203 [==============================] - 26s 130ms/step - loss: 0.9727 - accuracy: 0.6650 - val_loss: 1.0400 - val_accuracy: 0.6410\n",
      "Epoch 30/50\n",
      "203/203 [==============================] - 26s 130ms/step - loss: 0.9524 - accuracy: 0.6727 - val_loss: 1.0427 - val_accuracy: 0.6379\n",
      "Epoch 31/50\n",
      "203/203 [==============================] - 27s 131ms/step - loss: 0.9545 - accuracy: 0.6730 - val_loss: 1.0447 - val_accuracy: 0.6339\n",
      "Epoch 32/50\n",
      "203/203 [==============================] - 27s 135ms/step - loss: 0.9320 - accuracy: 0.6792 - val_loss: 1.0482 - val_accuracy: 0.6347\n",
      "Epoch 33/50\n",
      "203/203 [==============================] - 28s 138ms/step - loss: 0.9310 - accuracy: 0.6817 - val_loss: 1.0372 - val_accuracy: 0.6410\n",
      "Epoch 34/50\n",
      "203/203 [==============================] - 27s 131ms/step - loss: 0.9127 - accuracy: 0.6835 - val_loss: 1.0365 - val_accuracy: 0.6447\n",
      "Epoch 35/50\n",
      "203/203 [==============================] - 27s 131ms/step - loss: 0.9032 - accuracy: 0.6929 - val_loss: 1.0421 - val_accuracy: 0.6459\n",
      "Epoch 36/50\n",
      "203/203 [==============================] - 27s 131ms/step - loss: 0.8901 - accuracy: 0.6969 - val_loss: 1.0345 - val_accuracy: 0.6439\n",
      "Epoch 37/50\n",
      "203/203 [==============================] - 26s 130ms/step - loss: 0.8847 - accuracy: 0.7014 - val_loss: 1.0409 - val_accuracy: 0.6462\n",
      "Epoch 38/50\n",
      "203/203 [==============================] - 27s 131ms/step - loss: 0.9084 - accuracy: 0.6894 - val_loss: 1.0285 - val_accuracy: 0.6410\n",
      "Epoch 39/50\n",
      "203/203 [==============================] - 27s 133ms/step - loss: 0.8992 - accuracy: 0.6898 - val_loss: 1.0223 - val_accuracy: 0.6522\n",
      "Epoch 40/50\n",
      "203/203 [==============================] - 27s 134ms/step - loss: 0.8737 - accuracy: 0.7029 - val_loss: 1.0210 - val_accuracy: 0.6510\n",
      "Epoch 41/50\n",
      "203/203 [==============================] - 26s 130ms/step - loss: 0.8683 - accuracy: 0.7039 - val_loss: 1.0261 - val_accuracy: 0.6505\n",
      "Epoch 42/50\n",
      "203/203 [==============================] - 27s 131ms/step - loss: 0.8769 - accuracy: 0.7011 - val_loss: 1.0205 - val_accuracy: 0.6545\n",
      "Epoch 43/50\n",
      "203/203 [==============================] - 27s 131ms/step - loss: 0.8613 - accuracy: 0.7025 - val_loss: 1.0221 - val_accuracy: 0.6553\n",
      "Epoch 44/50\n",
      "203/203 [==============================] - 26s 128ms/step - loss: 0.8647 - accuracy: 0.7106 - val_loss: 1.0260 - val_accuracy: 0.6510\n",
      "Epoch 45/50\n",
      "203/203 [==============================] - 27s 134ms/step - loss: 0.8598 - accuracy: 0.7114 - val_loss: 1.0284 - val_accuracy: 0.6547\n",
      "Epoch 46/50\n",
      "203/203 [==============================] - 27s 135ms/step - loss: 0.8660 - accuracy: 0.7028 - val_loss: 1.0229 - val_accuracy: 0.6556\n",
      "Epoch 47/50\n",
      "203/203 [==============================] - 27s 132ms/step - loss: 0.8506 - accuracy: 0.7125 - val_loss: 1.0243 - val_accuracy: 0.6530\n",
      "Epoch 48/50\n",
      "203/203 [==============================] - 27s 134ms/step - loss: 0.8316 - accuracy: 0.7171 - val_loss: 1.0224 - val_accuracy: 0.6562\n",
      "Epoch 49/50\n",
      "203/203 [==============================] - 28s 136ms/step - loss: 0.8357 - accuracy: 0.7162 - val_loss: 1.0191 - val_accuracy: 0.6559\n",
      "Epoch 50/50\n",
      "203/203 [==============================] - 27s 131ms/step - loss: 0.8268 - accuracy: 0.7240 - val_loss: 1.0192 - val_accuracy: 0.6570\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=32, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions using the model and print out the confusion matrix and classification report results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "BPCWyEkOSXLo"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FxJXYpTydcHD",
    "outputId": "02129639-cb99-410d-9231-0338b316fae6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[276   0  17   0  16   1   7  21  13   2]\n",
      " [  0 312   7  18   4   0  15   9   1   1]\n",
      " [ 15  12 190  16  18   4  28  43  19   0]\n",
      " [  0  11  15 223  12   1  11  14  35  23]\n",
      " [  2   2  27  18 223   0   8  40  18   6]\n",
      " [  0   0   0   2   0 335   6   0   5  18]\n",
      " [  7  17  59  43  19   1 110   5  71   9]\n",
      " [ 17  16  32   6  51   0  13 195   7   3]\n",
      " [  6   3  20  32  30   1  25   3 197  27]\n",
      " [  0   0   3  29  12  25   3   0  43 236]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.78      0.82       353\n",
      "           1       0.84      0.85      0.84       367\n",
      "           2       0.51      0.55      0.53       345\n",
      "           3       0.58      0.65      0.61       345\n",
      "           4       0.58      0.65      0.61       344\n",
      "           5       0.91      0.92      0.91       366\n",
      "           6       0.49      0.32      0.39       341\n",
      "           7       0.59      0.57      0.58       340\n",
      "           8       0.48      0.57      0.52       344\n",
      "           9       0.73      0.67      0.70       351\n",
      "\n",
      "    accuracy                           0.66      3496\n",
      "   macro avg       0.66      0.65      0.65      3496\n",
      "weighted avg       0.66      0.66      0.66      3496\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(confusion_matrix(y_test,np.argmax(y_pred,axis=1)))\n",
    "print(classification_report(y_test,np.argmax(y_pred,axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manipulating the confusion matrix to print out average sensitivity and specificity scores for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "JHgpy65peQaH"
   },
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(y_test,np.argmax(y_pred,axis=1))\n",
    "\n",
    "FP = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix) \n",
    "FN = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix)\n",
    "TP = np.diag(cnf_matrix)\n",
    "TN = cnf_matrix.sum(axis=1) + cnf_matrix.sum(axis=0) - (FP + FN + TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "5x-G3DrHedhB"
   },
   "outputs": [],
   "source": [
    "FP = FP.astype(float)\n",
    "FN = FN.astype(float)\n",
    "TP = TP.astype(float)\n",
    "TN = TN.astype(float)\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP) \n",
    "# Precision or positive predictive value\n",
    "PPV = TP/(TP+FP)\n",
    "# Negative predictive value\n",
    "NPV = TN/(TN+FN)\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "# False negative rate\n",
    "FNR = FN/(TP+FN)\n",
    "# False discovery rate\n",
    "FDR = FP/(TP+FP)\n",
    "# Overall accuracy for each class\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nmAvGryfl0Mp",
    "outputId": "c1559ea0-a53c-4e16-9e5e-814879a56d5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6555689252430534 0.6533812885739544\n"
     ]
    }
   ],
   "source": [
    "print(TPR.mean(),TNR.mean())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "genreclassifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
